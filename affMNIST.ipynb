{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model, Model\n",
    "import numpy as np\n",
    "from utils.visualizations import GradCAM, GuidedGradCAM, GBP, LRP, CLRP, SGLRP, SGLRP2, OAGLRP\n",
    "from utils.helper import heatmap\n",
    "import innvestigate.utils as iutils\n",
    "import os\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "import math\n",
    "import scipy.io as sio\n",
    "import tqdm\n",
    "from utils.fileutils import CacheStorage\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (40, 40, 1)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_mat(data_dir):\n",
    "    mat_list = os.listdir(data_dir)\n",
    "    images = np.empty((0, input_shape[0]*input_shape[1]*input_shape[2]))\n",
    "    labels = np.empty((0,num_classes))\n",
    "    for mat_path in tqdm.tqdm(mat_list):\n",
    "        if mat_path.endswith('.mat'):\n",
    "            mat_contents = sio.loadmat(os.path.join(data_dir, mat_path))\n",
    "            data = mat_contents['affNISTdata'][0,0]\n",
    "            images = np.append(images, data['image'].T, axis=0)\n",
    "            labels = np.append(labels, data['label_one_of_n'].T, axis=0)\n",
    "    return images, labels\n",
    "# load_images_from_mat(os.path.join('data', 'affMNIST','test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affnist_images(data_dir, dataset):\n",
    "    imgs = []\n",
    "    labels = []\n",
    "\n",
    "    cache = CacheStorage()\n",
    "    print(\"Try to load cache file\")\n",
    "    imgs = cache.get_cache(os.path.join('cache', \"mnist_imgs_\"+dataset))\n",
    "    labels = cache.get_cache(os.path.join('cache', \"mnist_labels_\"+dataset))\n",
    "    if imgs is None or labels is None:\n",
    "        print(\"Making cache file\")\n",
    "        imgs, labels = load_images_from_mat(os.path.join(data_dir, dataset))\n",
    "        cache.set_cache(os.path.join('cache', \"mnist_imgs_\"+dataset), imgs)\n",
    "        cache.set_cache(os.path.join('cache', \"mnist_labels_\"+dataset), labels)\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try to load cache file\n",
      "Try to load cache file\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = get_affnist_images(os.path.join('data', 'affMNIST'), 'test')\n",
    "x_train, y_train = get_affnist_images(os.path.join('data', 'affMNIST'), 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920000, 1600)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 40, 40, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 40, 40, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 40, 40, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 20, 20, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 10, 10, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              6554624   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 9,348,810\n",
      "Trainable params: 9,348,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This will be your trained model instead.\n",
    "\n",
    "from utils.models import VGG10_nodrop, preprocess_input\n",
    "model = VGG10_nodrop(\n",
    "    input_shape=input_shape,\n",
    "    nb_class=num_classes\n",
    ")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocess_input(x_train, input_shape[0], input_shape[1], input_shape[2])\n",
    "x_test = preprocess_input(x_test, input_shape[0], input_shape[1], input_shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1919808 samples, validate on 192 samples\n",
      "Epoch 1/4\n",
      "1919808/1919808 [==============================] - 13949s 7ms/step - loss: 0.0638 - acc: 0.9797 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 2/4\n",
      "1919808/1919808 [==============================] - 15866s 8ms/step - loss: 0.0139 - acc: 0.9957 - val_loss: 0.0115 - val_acc: 0.9948\n",
      "Epoch 3/4\n",
      "1919808/1919808 [==============================] - 13555s 7ms/step - loss: 0.0088 - acc: 0.9973 - val_loss: 0.0171 - val_acc: 0.9948\n",
      "Epoch 4/4\n",
      "1919808/1919808 [==============================] - 13423s 7ms/step - loss: 0.0068 - acc: 0.9979 - val_loss: 0.0264 - val_acc: 0.9896\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard, CSVLogger, EarlyStopping\n",
    "\n",
    "nb_iterations = 50000\n",
    "learning_rate=0.0001\n",
    "batch_size=128\n",
    "nb_epochs = math.ceil(nb_iterations * (batch_size / x_train.shape[0]))\n",
    "dataset_prefix=\"affmnist\"\n",
    "\n",
    "save=True\n",
    "train=True\n",
    "\n",
    "validation_split=0.0001\n",
    "\n",
    "if not os.path.exists(os.path.join(\"logs\", \"%s\" % (dataset_prefix))):\n",
    "    os.mkdir(os.path.join(\"logs\", \"%s\" % (dataset_prefix)))\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", \"%s\" % (dataset_prefix)), batch_size=batch_size)\n",
    "csv_logger = CSVLogger(os.path.join('logs', '%s.csv' % (dataset_prefix)))\n",
    "\n",
    "if not save:\n",
    "    callback_list = []\n",
    "else:\n",
    "    callback_list = [tensorboard, csv_logger]\n",
    "    #callback_list = [model_checkpoint, reduce_lr, tensorboard, csv_logger]\n",
    "\n",
    "\n",
    "optm = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optm, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "if train:\n",
    "    #train\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epochs, callbacks=callback_list, verbose=1, validation_split=validation_split)\n",
    "    if save:\n",
    "        model.save_weights(os.path.join(\"weights\", \"%s_val_loss_weights_final.h5\" % (dataset_prefix)))\n",
    "else: \n",
    "        model.load_weights(os.path.join(\"weights\", \"%s_val_loss_weights_final.h5\" % (dataset_prefix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 40, 40, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 40, 40, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 40, 40, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 20, 20, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 10, 10, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 10, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              6554624   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 9,348,810\n",
      "Trainable params: 9,348,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Only the partial model is needed for the visualizers. Use innvestigate.utils.keras.graph.pre_softmax_tensors()\n",
    "partial_model = Model(\n",
    "    inputs=model.inputs,\n",
    "    outputs=iutils.keras.graph.pre_softmax_tensors(model.outputs),\n",
    "    name=model.name,\n",
    ")\n",
    "partial_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of input images\n",
    "# keras_applications VGG16 weights assume a range of (-127.5, 127.5). Change this to a range suitable for your model.\n",
    "max_input = -1.\n",
    "min_input = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 40, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "# Change this to load a list of images you want. For this example, we are only loading one image, but you can load a list of files.\n",
    "orig_imgs = x_test\n",
    "input_imgs = np.copy(orig_imgs[:200])\n",
    "print(np.shape(input_imgs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only one from your list for example\n",
    "example_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(orig_imgs[example_id].reshape((input_shape[0],input_shape[1])), cmap=\"Greys_r\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradCAM and GuidedGradCAM requires a specific layer\n",
    "target_layer = \"max_pooling2d_3\" # VGG only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "predictions = model.predict(input_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(predictions):\n",
    "    if np.max(p) < 1. :\n",
    "        print(i, np.max(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability: 1.0\n",
      "prediction id: 0\n",
      "target id: 0\n"
     ]
    }
   ],
   "source": [
    "# Which class you want to target.\n",
    "target_class = 0\n",
    "\n",
    "pred_id = np.argmax(predictions[example_id])\n",
    "print(\"probability:\", predictions[example_id][target_class])\n",
    "print(\"prediction id:\", pred_id)\n",
    "print(\"target id:\", target_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "partial_gradcam_analyzer = GradCAM(\n",
    "    model=partial_model,\n",
    "    target_id=target_class,\n",
    "    layer_name=target_layer,\n",
    "    relu=True,\n",
    ")\n",
    "analysis_partial_grad_cam = partial_gradcam_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_partial_grad_cam[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "guidedbackprop_analyzer = GBP(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=True,\n",
    ")\n",
    "analysis_guidedbackprop = guidedbackprop_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_guidedbackprop[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GuidedGradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "guidedgradcam_analyzer = GuidedGradCAM(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    layer_name=target_layer,\n",
    "    relu=True,\n",
    ")\n",
    "analysis_guidedgradcam = guidedgradcam_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_guidedgradcam[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrp_analyzer = LRP(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=True,\n",
    "    low=min_input,\n",
    "    high=max_input,\n",
    ")\n",
    "analysis_lrp = lrp_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_lrp[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clrp_analyzer = CLRP(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=True,\n",
    "    low=min_input,\n",
    "    high=max_input,\n",
    ")\n",
    "analysis_clrp = clrp_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_clrp[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGLRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sglrp_analyzer = SGLRP(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=True,\n",
    "    low=min_input,\n",
    "    high=max_input,\n",
    ")\n",
    "analysis_sglrp = sglrp_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_sglrp[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oaglrp_analyzer = OAGLRP(\n",
    "#     partial_model,\n",
    "#     target_id=target_class,\n",
    "#     relu=False,\n",
    "#     scaling=False,\n",
    "#     low=min_input,\n",
    "#     high=max_input,\n",
    "# )\n",
    "# analysis_oaglrp = oaglrp_analyzer.analyze(input_imgs)\n",
    "# heatmap(analysis_oaglrp[example_id].sum(axis=(2)))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

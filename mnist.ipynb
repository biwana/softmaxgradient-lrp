{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model, Model\n",
    "import numpy as np\n",
    "from utils.visualizations import GradCAM, GuidedGradCAM, GBP, LRP, CLRP, SGLRP, SGLRP2, OAGLRP\n",
    "from utils.helper import heatmap\n",
    "import innvestigate.utils as iutils\n",
    "import os\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import math\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,817,610\n",
      "Trainable params: 1,817,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# This will be your trained model instead.\n",
    "\n",
    "from utils.models import LeNet, preprocess_input\n",
    "model = LeNet(\n",
    "    input_shape=(img_rows, img_cols, 1),\n",
    "    nb_class=num_classes\n",
    ")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocess_input(x_train, img_rows, img_cols, 1)\n",
    "x_test = preprocess_input(x_test, img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard, CSVLogger, EarlyStopping\n",
    "\n",
    "nb_iterations = 50000\n",
    "learning_rate=0.0001\n",
    "batch_size=128\n",
    "nb_epochs = math.ceil(nb_iterations * (batch_size / x_train.shape[0]))\n",
    "dataset_prefix=\"mnist\"\n",
    "\n",
    "save=False\n",
    "train=False\n",
    "\n",
    "validation_split=0.0025\n",
    "\n",
    "if not os.path.exists(os.path.join(\"logs\", \"%s\" % (dataset_prefix))):\n",
    "    os.mkdir(os.path.join(\"logs\", \"%s\" % (dataset_prefix)))\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", \"%s\" % (dataset_prefix)), batch_size=batch_size)\n",
    "csv_logger = CSVLogger(os.path.join('logs', '%s.csv' % (dataset_prefix)))\n",
    "\n",
    "if not save:\n",
    "    callback_list = []\n",
    "else:\n",
    "    callback_list = [tensorboard, csv_logger]\n",
    "    #callback_list = [model_checkpoint, reduce_lr, tensorboard, csv_logger]\n",
    "\n",
    "\n",
    "optm = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optm, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "if train:\n",
    "    #train\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epochs, callbacks=callback_list, verbose=1, validation_split=validation_split)\n",
    "    if save:\n",
    "        model.save_weights(os.path.join(\"weights\", \"%s_val_loss_weights_final.h5\" % (dataset_prefix)))\n",
    "else: \n",
    "        model.load_weights(os.path.join(\"weights\", \"%s_val_loss_weights_final.h5\" % (dataset_prefix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,817,610\n",
      "Trainable params: 1,817,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Only the partial model is needed for the visualizers. Use innvestigate.utils.keras.graph.pre_softmax_tensors()\n",
    "partial_model = Model(\n",
    "    inputs=model.inputs,\n",
    "    outputs=iutils.keras.graph.pre_softmax_tensors(model.outputs),\n",
    "    name=model.name,\n",
    ")\n",
    "partial_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of input images\n",
    "# keras_applications VGG16 weights assume a range of (-127.5, 127.5). Change this to a range suitable for your model.\n",
    "max_input = -1.\n",
    "min_input = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Change this to load a list of images you want. For this example, we are only loading one image, but you can load a list of files.\n",
    "orig_imgs = x_test\n",
    "input_imgs = np.copy(orig_imgs[:200])\n",
    "print(np.shape(input_imgs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only one from your list for example\n",
    "example_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(orig_imgs[example_id].reshape((img_rows,img_cols)), cmap=\"Greys_r\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradCAM and GuidedGradCAM requires a specific layer\n",
    "target_layer = \"max_pooling2d_3\" # VGG only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "predictions = model.predict(input_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0.9999995\n",
      "62 0.9999932\n",
      "92 0.99998\n",
      "95 0.9999937\n",
      "115 0.9909313\n",
      "121 0.99999976\n",
      "158 0.99475527\n",
      "175 0.99222976\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(predictions):\n",
    "    if np.max(p) < 1. :\n",
    "        print(i, np.max(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability: 3.0780548e-23\n",
      "prediction id: 7\n",
      "target id: 3\n"
     ]
    }
   ],
   "source": [
    "# Which class you want to target.\n",
    "target_class = 3\n",
    "\n",
    "pred_id = np.argmax(predictions[example_id])\n",
    "print(\"probability:\", predictions[example_id][target_class])\n",
    "print(\"prediction id:\", pred_id)\n",
    "print(\"target id:\", target_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "partial_gradcam_analyzer = GradCAM(\n",
    "    model=partial_model,\n",
    "    target_id=target_class,\n",
    "    layer_name=target_layer,\n",
    "    relu=True,\n",
    ")\n",
    "analysis_partial_grad_cam = partial_gradcam_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_partial_grad_cam[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "guidedbackprop_analyzer = GBP(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=True,\n",
    ")\n",
    "analysis_guidedbackprop = guidedbackprop_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_guidedbackprop[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GuidedGradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "guidedgradcam_analyzer = GuidedGradCAM(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    layer_name=target_layer,\n",
    "    relu=True,\n",
    ")\n",
    "analysis_guidedgradcam = guidedgradcam_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_guidedgradcam[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it was empty\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAEYCAYAAACHjumMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAA9FJREFUeJzt17FNw1AUhlEbMYKpeUOg7F9HDGFqvMPLCImRPqFE59R/catPuuuccwEovP33AcDrEhggIzBARmCAjMAAGYEBMgIDZAQGyAgMkHk/M962bY4xolOAZ7Hv+3Icx3pvdyowY4zl+3r9+1XAS/i6XB7aeZGAjMAAGYEBMgIDZAQGyAgMkBEYICMwQEZggIzAABmBATICA2QEBsgIDJARGCAjMEBGYICMwAAZgQEyAgNkBAbICAyQERggIzBARmCAjMAAGYEBMgIDZAQGyAgMkBEYICMwQEZggIzAABmBATICA2QEBsgIDJARGCAjMEBGYICMwAAZgQEyAgNkBAbICAyQERggIzBARmCAjMAAGYEBMgIDZAQGyAgMkBEYICMwQEZggIzAABmBATICA2QEBsgIDJARGCAjMEBGYICMwAAZgQEyAgNkBAbICAyQERggIzBARmCAjMAAGYEBMgIDZAQGyAgMkBEYICMwQEZggIzAABmBATICA2QEBsgIDJARGCAjMEBGYICMwAAZgQEyAgNkBAbICAyQERggIzBARmCAjMAAGYEBMgIDZAQGyAgMkBEYICMwQEZggIzAABmBATICA2QEBsgIDJARGCAjMEBGYICMwAAZgQEyAgNkBAbICAyQERggIzBARmCAjMAAGYEBMgIDZAQGyAgMkBEYICMwQEZggIzAABmBATICA2QEBsgIDJARGCAjMEBGYICMwAAZgQEyAgNkBAbICAyQERggIzBARmCAjMAAGYEBMgIDZAQGyAgMkBEYICMwQEZggIzAABmBATICA2QEBsgIDJARGCAjMEBGYICMwAAZgQEyAgNkBAbICAyQERggIzBARmCAjMAAGYEBMgIDZAQGyAgMkBEYICMwQEZggIzAABmBATICA2QEBsgIDJARGCAjMEBGYICMwAAZgQEyAgNkBAbICAyQERggIzBARmCAjMAAGYEBMgIDZAQGyAgMkBEYICMwQEZggIzAABmBATICA2QEBsgIDJARGCAjMEBGYICMwAAZgQEyAgNkBAbICAyQERggIzBARmCAjMAAGYEBMgIDZAQGyAgMkBEYICMwQEZggIzAABmBATICA2QEBsgIDJARGCAjMEBGYICMwAAZgQEyAgNkBAbICAyQERggIzBARmCAjMAAGYEBMgIDZAQGyAgMkBEYICMwQEZggIzAABmBATICA2QEBsgIDJARGCAjMEBGYIDMOud8fLyuv8uy/HTnAE/ic875cW90KjAAZ3iRgIzAABmBATICA2QEBsgIDJARGCAjMEBGYIDMDd9+Gon+esmGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrp_analyzer = LRP(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=True,\n",
    "    low=min_input,\n",
    "    high=max_input,\n",
    ")\n",
    "analysis_lrp = lrp_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_lrp[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clrp_analyzer = CLRP(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=True,\n",
    "    low=min_input,\n",
    "    high=max_input,\n",
    ")\n",
    "analysis_clrp = clrp_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_clrp[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGLRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sglrp_analyzer = SGLRP(\n",
    "    partial_model,\n",
    "    target_id=target_class,\n",
    "    relu=True,\n",
    "    low=min_input,\n",
    "    high=max_input,\n",
    ")\n",
    "analysis_sglrp = sglrp_analyzer.analyze(input_imgs)\n",
    "heatmap(analysis_sglrp[example_id].sum(axis=(2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oaglrp_analyzer = OAGLRP(\n",
    "#     partial_model,\n",
    "#     target_id=target_class,\n",
    "#     relu=False,\n",
    "#     scaling=False,\n",
    "#     low=min_input,\n",
    "#     high=max_input,\n",
    "# )\n",
    "# analysis_oaglrp = oaglrp_analyzer.analyze(input_imgs)\n",
    "# heatmap(analysis_oaglrp[example_id].sum(axis=(2)))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
